{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[C5W3L07 Attention Model Intuition](https://www.youtube.com/watch?v=SysgYptB198)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding/decoding expensive.  \n",
    "RNNs can't easily keep track of long-term past.  \n",
    "performance when they are asked to do so drops off substantially."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine the attention to pay to each input for each output. for example: how relevant is the first input as we try to determine the first output?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each output depends on:  \n",
    "1. the immediately priorr output.\n",
    "2. the context, which is a function of the values and attention of each of the inputs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[C5W3L08 Attention Model](https://www.youtube.com/watch?v=quoGRI-1l0A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the attention values sum to one: what percent of my attention should I put on this particular input as I try to determine the next output?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now understand well why we would want something like attention; I still don't understand how the attention matrix is calculated. it seems like it might depend on the structure of the network in which it's used, too: there is probably not one all-purpose \"attention\" algorithm just as there is not all-purpose \"neural network\" architecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Attention in Neural Networks](https://www.youtube.com/watch?v=W2rWgXJBZhU)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "focus in high res on certain parts of the input and only in low res on the rest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Transformer Neural Networks - EXPLAINED! (Attention is all you need)](https://www.youtube.com/watch?v=TQQlZhbC5ps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "disadvantages of RNNs:\n",
    "1. slow to train. lots of computation.  \n",
    "2. long sequences lead to vanishing or exploding gradients, so it's hrad to keep track of much context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs allow memory to be retained for longer sequences.  \n",
    "even slower than RNNs, though."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sequential flow of inputs does not take advantage of parallelization in modern GPUs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the word embeddings are all determined simultaneously with a transformer encoder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in NLP, we take the semantic embedding of a word, which gives it a vector value that is similar to the vector values of similar words. we also give it a positional encoding, which keeps track of its position in the sentence. we combine these to get an embedding of the word's sematics WITH CONTEXT INFO. nice!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self-attention: how relevant is this input to the other inputs later or earlier in the sequence?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reflection:\n",
    "I think I understand attention intuitively well, but not mathematically well. I'll return to this when I've finished the rest of the course I'm working on. we use attention to determine which parts of the input bear most on our current output. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
