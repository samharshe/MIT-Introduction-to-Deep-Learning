{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Lecture 10: Practical Uncertainty Estimates and Out-of-Distribution Robustness in Deep Learning](https://www.youtube.com/watch?v=veYq6EWZyVc&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncertainty: return a distribution of predictions rather than a single prediction.  \n",
    "classification: label + confidence.  \n",
    "regression: mean + variance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out-of-distribution robustness:  \n",
    "IID = independent and identically distributed = assumption that test and training distributions are the same.  \n",
    "OOD = that assumption fails."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset shift:  \n",
    "distribution of features p(x) changes and p(y|x) is fixed.  \n",
    "open-set recognition: new classes appear at test-time.  \n",
    "label shift: distribution of labels p(y) changes and p(x|y) is fixed. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converational dialogue systems: detect out-of-scope questions and decline to answer them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model uncertainty = epistemic uncertainty = reducible.  \n",
    "data uncertainty = aleatoric uncertainty = irreducible.  \n",
    "ex: label noise, measurement noise, missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calibration error = |confidence - accuracy|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this does not account for accuracy at all: we could have a model that knows nothing but knows that it knows nothing and has a very low calibration error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural networks with SGD can estimate the distribution of the parameters.  \n",
    "ensembling: obtain multiple good settings for the parameters and see whether their predictions converge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training time: calculate the conditional likelihood of the paremeters given the observations.  \n",
    "prediction time: calculate the likelihood of of an output given the input and distribution of parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensembling: \"find a bunch of ways of making predictions and see how mucb these models converge on a given input\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo dropout: only do dropout in testing, which gives you an ensemble-like set of predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep ensemble: train the model 5-10 times, only varying the initial randomization of parameters.  \n",
    "hyperparameter ensemble: train a few models with different hyperparameters. (\"broaden the model hypothesis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale is a problem: it's slow and expensive to train so many models and make so many predictions when models are employed.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-training: instead of just training on the data you have that applies directly to the problem, train on some huge dataset you can get your hands on (eg the entire internet), then retrain just the last layer (ish) on the specific data you have.  \n",
    "either we can do all this fancy math to deal with out of distribution inputs, or we can get our hands on the whole distribution!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reflection:  \n",
    "\n",
    "a lot of this was covered in lecture 5, but it was such a clear delivery that I still enjoyed it a lot.  \n",
    "the concepts were explained intuitvely enough I don't feel the need to recapitulate the technical details here.  \n",
    "we want to be humble when operating on data outside the distribution we've trained on.  \n",
    "there are two main ways of estimating uncertainty in-distribution: holding the distribution of the parameters, and ensembling.  \n",
    "scale is a problem because there is so much redundancy in ensembling and so much information to keep track of if you hold the distribution of the parameters, but often the models are so much better it's worth it.  \n",
    "this is an important area.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
